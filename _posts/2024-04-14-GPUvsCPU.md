# The competition base on bird 

## CPU

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.076692</td>
      <td>0.025803</td>
      <td>0.005155</td>
      <td>00:54</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.037787</td>
      <td>0.020217</td>
      <td>0.010309</td>
      <td>00:55</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.020219</td>
      <td>0.012819</td>
      <td>0.007732</td>
      <td>00:57</td>
    </tr>
  </tbody>
</table>

## GPU

default batch size is 64

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.050168</td>
      <td>0.032649</td>
      <td>0.013769</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.032566</td>
      <td>0.017594</td>
      <td>0.005164</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.018081</td>
      <td>0.010844</td>
      <td>0.005164</td>
      <td>00:05</td>
    </tr>
  </tbody>
</table>


![nvtop](/images/2024-04-14-GPUvsCPU/image.png)
In the nvtop image above, we can find four peaks of GPU load, which represents four epochs, the first one is the first learning of `vision_learner`, and the next three is the fine tune learning. 

And we can find GPU improve the efficiency a lot. The time reduces down to 0.05 from 0.55.

### changing batch 

**Step1, enlarge shm size to 8g.**\
Still take 5 second every epoch. So the shm size is not a factor in this case.

**Step2, changing batch to 16, 32, 64, 128, and 256.**\
We can find that default `bs:int=64` in the documentation from [datablock.dataloaders](https://docs.fast.ai/data.block.html#datablock.dataloaders).\
To put in user defined batch, we input like `dataloaders(path,bs=16)` to set batch 16.

And here is result:

**Batch 16:**
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.088062</td>
      <td>0.016613</td>
      <td>0.006885</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.056767</td>
      <td>0.025430</td>
      <td>0.010327</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.037358</td>
      <td>0.013636</td>
      <td>0.006885</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>

![nvtop](/images/2024-04-14-GPUvsCPU/image16.png)

**Batch 32:**
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.053868</td>
      <td>0.035767</td>
      <td>0.005164</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.031391</td>
      <td>0.002464</td>
      <td>0.000000</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.015201</td>
      <td>0.004653</td>
      <td>0.003442</td>
      <td>00:05</td>
    </tr>
  </tbody>
</table>

![nvtop](/images/2024-04-14-GPUvsCPU/image32.png)

**Batch 64:**
same as [GPU](#gpu)


**Batch 128:**
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.040779</td>
      <td>0.017250</td>
      <td>0.006885</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.021003</td>
      <td>0.008894</td>
      <td>0.003442</td>
      <td>00:05</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.012052</td>
      <td>0.007208</td>
      <td>0.003442</td>
      <td>00:05</td>
    </tr>
  </tbody>
</table>

![nvtop](/images/2024-04-14-GPUvsCPU/image128.png)


**Batch 256:**
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.050352</td>
      <td>0.035848</td>
      <td>0.006885</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.027607</td>
      <td>0.011125</td>
      <td>0.006885</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.017746</td>
      <td>0.014662</td>
      <td>0.006885</td>
      <td>00:06</td>
    </tr>
  </tbody>
</table>

![nvtop](/images/2024-04-14-GPUvsCPU/image256.png)


We compare batch 16 with batch 256, because these two batch has the largest difference. We can find:

- The time of each epoch is a little shorter for batch 256, reduce from 0.07 to 0.06.
- As for GPU load, batch 256 takes around 90% while batch 16 only use 50%. 
- And for GPU mem, batch 256's mem load rises to 75% when training. But batch 16's mem keep 25% through all the training process.

So, if we set larger batch, that means we are training with more concurrency. Then the load of GPU increase, and the efficiency improves as well.
